{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3673a923-d83f-4cb2-9206-575aa3c7a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf9b0f-d482-4b23-86ad-9d72eb3c2c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using GPU: Metal Performance Shaders (MPS)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Tensor creation\n",
    "x = tensor([1.0, 2.0, 3.0], device=device, dtype=dtype)\n",
    "print(f\"Tensor: {x}, Device: {x.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509ca03-73eb-4152-9338-d4cc1a279b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is MPS even available? macOS 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# Was the current version of PyTorch built with MPS activated?\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac987556-ef9a-4895-958f-a60cd178339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading torch modules\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6051e-c142-438b-9266-fab5496c060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your dataset in the Downloads folder\n",
    "dataset_path = \"/Users/jalajtrivedi/Downloads/inaturalist_12K\"\n",
    "\n",
    "# Define transformations (e.g., resizing, normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Load training and validation datasets\n",
    "train_dataset = datasets.ImageFolder(root=f\"{dataset_path}/train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=f\"{dataset_path}/val\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251af689-47d3-450e-8eff-52a48188d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326bf8f-e9d5-4995-956f-2f2b7a92402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339acfb5-dbf2-4dc1-b6af-cb31abd31d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f034b-2039-41a8-b3cf-550aafbe6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "image,label = train_dataset[0]\n",
    "print(image.shape)\n",
    "print(label)\n",
    "print(train_dataset.classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf3afa-ce0a-4d54-92d6-12ad6fc634bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,drop_last=False)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=32, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f131aa-7741-43d2-b128-787027fc9eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No.of batches in train data:\",len(train_loader))\n",
    "print(\"No.of batches in val data:\",len(validation_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a45fed-4817-4dc3-a27a-892cb3bee413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing 1 batch of training data\n",
    "images,labels = next(iter(train_loader))\n",
    "print('Size of batch',images.shape)\n",
    "print('Size of labels',labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3631d2cc-c7c0-472d-a83e-ae92fbfe6370",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ed2bb-52ef-4ea7-bba7-3cf49d2a544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(x_t)\n",
    "\n",
    "fig,ax = plt.subplots(1,4,figsize=(8,10))\n",
    "i = 0\n",
    "for i, (img, label) in enumerate(zip(imgs[:4], labels[:4])):\n",
    "    img = img/2 +0.5\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    npimg = img.numpy()\n",
    "    ax[i].imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    ax[i].set_xlabel(train_dataset.classes[label])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1da7f-78ee-4b4d-9ec3-0a1ee5e828ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finetunning a pretrained model(resnet50)\n",
    "from torchvision import models\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae783d-3eb6-4594-b8b2-b300f6e78a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccc3de-fd3c-4d2e-9b72-19285a9b63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze the parameters of the pre-trained layers\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# for param in resnet50.layer2.parameters():\n",
    "#     param.requires_grad = True  # Unfreeze layer2 onwards\n",
    "\n",
    "# for param in resnet50.layer3.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "for param in resnet50.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move the model to the correct device\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f4e92-8b4f-43c2-aeb6-93a9d7541735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training Data:\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(),lr=0.001,momentum=0.9)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses = []\n",
    "best_val_loss = float('inf')  # Initialize with a very large value\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    resnet50.train()\n",
    "    \n",
    "    # Initialize the training loss accumulator to zero\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0.0\n",
    "    total_samples = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader,0):\n",
    "        # Prepare data and send it to the proper device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear the gradients of all optimized parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: obtain model predictions for the input data\n",
    "        outputs = resnet50(inputs)\n",
    "\n",
    "        # Compute the loss between the model predictions and the true labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Backward pass: compute gradients of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters using the computed gradients and the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy\n",
    "        class_correct = torch.argmax(outputs, axis=1) == labels\n",
    "        running_correct += torch.count_nonzero(class_correct)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Metrics for the epoch\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_accuracy = running_correct / total_samples\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Training Loss: {epoch_loss:.3f}, Training Accuracy: {epoch_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248fb61-e3db-4dc8-b593-2ec4224b6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the correct device\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "resnet50.eval()\n",
    "val_loss = 0.0\n",
    "val_correct = 0.0\n",
    "total_samples = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_loader:\n",
    "        # Prepare data and send it to the proper device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass: obtain model predictions for the input data\n",
    "        outputs = resnet50(inputs)\n",
    "\n",
    "        # Compute the loss between the model predictions and the true labels\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Update the validation loss\n",
    "        val_loss += loss.item()* inputs.size(0)\n",
    "        \n",
    "        # Calculate how many images were correctly classified\n",
    "        class_correct = torch.argmax(outputs, axis=1) == labels\n",
    "        val_correct += torch.count_nonzero(class_correct)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "# Calculate validation loss\n",
    "val_loss /= total_samples\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_acc = val_correct / total_samples\n",
    "# Print validation loss and accuracy\n",
    "print(f\"Validation Loss: {val_loss:.3f}, Validation Accuracy: {val_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
